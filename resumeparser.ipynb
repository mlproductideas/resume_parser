{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\yskvi\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from sentence_transformers) (0.11.3)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from sentence_transformers) (0.1.96)\n",
      "Requirement already satisfied: nltk in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from sentence_transformers) (3.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from sentence_transformers) (0.24.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.47.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.17.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.5.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.18.5)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.10.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2020.6.8)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.47)\n",
      "Requirement already satisfied: requests in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.24.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.11.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.4.7)\n",
      "Requirement already satisfied: click in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from nltk->sentence_transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from nltk->sentence_transformers) (0.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
      "Requirement already satisfied: six in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\yskvi\\anaconda3\\lib\\site-packages (from torchvision->sentence_transformers) (7.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yskvi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "! pip install sentence_transformers\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "from re import sub\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yskvi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevanceScore:\n",
    "    \n",
    "    def __init__(self,resume_name,jd_name):\n",
    "        self.resume_name = resume_name\n",
    "        self.jd_name = jd_name\n",
    "    \n",
    "    def pdfTextExtract(self,path):\n",
    "        with open(path, 'rb') as f:\n",
    "            pdf = PdfFileReader(f)\n",
    "            countpage=pdf.getNumPages()\n",
    "            count=0\n",
    "            jd_text=[]\n",
    "\n",
    "            while count < countpage:    \n",
    "                pageObj = pdf.getPage(count)\n",
    "                count +=1\n",
    "                t = pageObj.extractText()\n",
    "\n",
    "                jd_text.append(t)\n",
    "            return jd_text\n",
    "\n",
    "\n",
    "    def conversion(self,file):\n",
    "        text = self.pdfTextExtract(file) \n",
    "        text = str(text)\n",
    "        text = text.replace(\"\\\\n\", \"\")\n",
    "        text = text.lower()\n",
    "        cleaned_text=re.split(' ; | , | . | | : | / | - ',text)\n",
    "        bad_chars = [';', ':', '!', \"*\",\",\",\".\",\"[\",'\"',\"'\",\"]\"]\n",
    "\n",
    "        for i in range(len(cleaned_text)):\n",
    "            for j in bad_chars:\n",
    "                cleaned_text[i]=cleaned_text[i].replace(j,'')\n",
    "        stop_words = list(set(stopwords.words('english')))\n",
    "\n",
    "#         for i in cleaned_text:\n",
    "#             if i in stop_words:\n",
    "#                 cleaned_text.remove(i)\n",
    "        cleaned_text=[i for i in cleaned_text if i]\n",
    "        cleaned_text=' '.join([str(elem) for elem in cleaned_text])\n",
    "        print(\"cleaned_text \",cleaned_text)\n",
    "        return cleaned_text\n",
    "\n",
    "    def PrintStats(self,resume_name,text1):\n",
    "        keyword_dict = pd.read_csv('template.csv')\n",
    "        \n",
    "        front_end_words = [nlp(text) for text in keyword_dict['front_end'].dropna(axis = 0)]\n",
    "        back_end_words = [nlp(text) for text in keyword_dict['back_end'].dropna(axis = 0)]\n",
    "        de_words = [nlp(text) for text in keyword_dict['data_engineer'].dropna(axis = 0)]\n",
    "        ds_words = [nlp(text) for text in keyword_dict['data_science'].dropna(axis = 0)]\n",
    "\n",
    "        matcher = PhraseMatcher(nlp.vocab,attr='LOWER')\n",
    "        matcher.add('FrontEnd', None, *front_end_words)\n",
    "        matcher.add('BackEnd', None, *back_end_words)\n",
    "        matcher.add('DE', None, *de_words)\n",
    "        matcher.add('DS', None, *ds_words)\n",
    "        doc = nlp(text1)\n",
    "        \n",
    "        d = []  \n",
    "        matches = matcher(doc)\n",
    "        for match_id, start, end in matches:\n",
    "            rule_id = nlp.vocab.strings[match_id]\n",
    "            span = doc[start : end]\n",
    "            d.append((rule_id, span.text))      \n",
    "        keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
    "\n",
    "        df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
    "        df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
    "        df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
    "        df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
    "        df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
    "\n",
    "  \n",
    "        filename = self.resume_name\n",
    "        name = filename.split('_')\n",
    "        name2 = name[0]\n",
    "        name2 = name2.lower()\n",
    "        name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
    "\n",
    "        dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "        dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "    \n",
    "        print(dataf)\n",
    "\n",
    "\n",
    "    def relevance(self,resume,jd):\n",
    "        model = SentenceTransformer('stsb-roberta-large')\n",
    "        def sent_simi_score(sent1, sent2):\n",
    "            #encode sentences to get their embeddings\n",
    "            embedding1 = model.encode(sent1, convert_to_tensor=True)\n",
    "            embedding2 = model.encode(sent2, convert_to_tensor=True)\n",
    "\n",
    "            # compute similarity scores of two embeddings\n",
    "            cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "\n",
    "            return cosine_scores.item()\n",
    "        \n",
    "        return sent_simi_score(resume,jd)\n",
    "\n",
    "\n",
    "    def start_method(self):\n",
    "        \n",
    "        text1 = self.conversion(resumes_path+\"\\\\\"+self.resume_name)\n",
    "        text2 = self.conversion(jd_path+\"\\\\\"+self.jd_name)\n",
    "        #print(\"tefgreg\",text1,\"fsrf\",text2)\n",
    "        relevance_score = self.relevance(text1,text2)\n",
    "        stats=self.PrintStats(self.resume_name,text1)\n",
    "        return relevance_score,text1,text2,stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_text  sai krishna vivek +91-9701508517 linkedincom/in/yskvivek yskvivek9@gmailcom profile 2+ years experience data engineering machine learning using spark hadoop technologies strong knowledge financial analytics banking domain currently pursuing masters analytics georgia tech special electives finance time series modelling excellent organizational analytical problem-solving presentation skills experience handling multiple stake holders proactive fast learner committed learning new technologies well adept switching domains fast learning curve responsible developing first its kind analytics product finance is completely based open source technologies responsible developing efficient multilevel chemical structure-based search web application million-compound dataset csir iict part research internship education master science analytics (online) 2021(expected) georgia institute technology (35 gpa) bachelor technology (computer science engineering) 2018 gokaraju rangaraju institute engineering technology affiliated jntu (86%) intermediate narayana junior college hyderabad (905%) 2014 10th (cbse) jubilee hills public school hyderabad (10 cgpa) 2012 additional qualifications technology entrepreneurship program 2018 indian school business (isb) hyderabad (a grade) oracle certified associate (sql/plsql) skill summary big data technologies spark 24 pyspark hive impala cloud services amazon s3 storage amazon ec2 amazon emr programming languages python 3 r java c++ python libraries numpy pandas scikit scipy keras cran performanceanalytics frf2 lubridate visualization tools d3 tableau rdbms mariadb postgresql project management/dev tools eclipse github tortoise svn maven jenkins jira confluence professional experience data engineer july 2018 current development bank singapore dbs (domain banking finance) hyderabad project strategic cost allocation group finance technologies spark 24 pyspark hadoop hive impala mariadb drools java 8 python 3 sql tableau d3 shell scripting developing cost allocation product an enterprise level replacing multiple legacy applications using bigdata technologies like spark hive impala building configurable parametrized scalable robust pipelines/etl workflows structuring massive amounts multi-structured data living multiple disparate systems using data modelling techniques pyspark involved visualization reporting using tools like d3 tableau involved migration current on-premises cloud (aws) large enterprise environment replacing multiple legacy applications using bigdata technologies performing extensive exploratory data analysis close 12 billion data using sql hive providing key insights decision making multiple dimensions (customer segment product segment process segment etc) an olap data cube working multiple stakeholders business teams globally (singapore hong kong india) schema design data modelling developed rule engine using drools efficiently process complex conditions unravelled python code documentation 25 different modules poc developed multiple pocs using machine learning models part internal hackathons well versed agile methodologies (scrum kanban agile pods) using tools like jira confluence tribe/squad model projects masters 1 comparative study performance football teams using spectral clustering(graph) python 2 performed manifold learning using isomap algorithm large dataset 10000 images python 3 comparative study naïve bayes logistic regression knn xgboost classifiers predicting employee turnover 4 itinerary planner using google maps nearest neighbours python flask d3js 5 market performance comparison berkshire hathaway s&p500 based sharpe ratio treynor using performanceanalytics lubridate package r 6 handwritten digits image classification using means clustering convoluted neural networks python (keras) 7 density estimation using multidimensional gaussian kernel study whether not two brain regions likely be independent each 8 expectation maximization using gaussian mixture model handwritten digits mnist dataset python 9 analysed facebook advertising data based cost per click cost per mil cost per conversion return advertising spent etc r also performed feature selection using fractional factorial design r 10 comparative study regression tree model random forest german credit data loan approval 11 comparative study logistic regression svm xgboost credit defaulters python 12 regression working hours vs salary wage workers new jersey philadelphia by dividing workers treatment control groups 13 performed weather predictions atlanta weather data using holtwinters exponential smoothing r 14 comparative study cusum arima garch to observe the changes temperature atlanta 15 a/b testing banner ads on georgia tech website r awards stood 4th among 30 teams dbs kiosk analytics 24hrs internal hackathon\n",
      "cleaned_text  job description search an experienced product manager lead multi-disciplinary development team an ideal candidate will keen eye gaps highly skilled market analyst proven ability strategize full lifecycle product production conception release may already confident leader has experience guiding cross-functional teams successful creation products improve consumer experience grow market share objectives this role drive product business-planning process across cross-functional teams the company analyze consumer needs current market trends potential partnerships an roi build vs buy perspective assess current competitor offerings seeking opportunities differentiation analyze product requirements develop appropriate programs develop implement maintain production timelines across multiple departments appraise new product ideas strategize appropriate to-market plans daily monthly responsibilities drive the execution product lifecycle processes products including product research market research competitive analysis planning positioning roadmap development requirements development product launch translate product strategy detailed requirements prototype construction final product development engineering teams create product strategy documents describe business cases high-level use cases technical requirements revenue roi analyze market data develop sales strategies define product objectives effective marketing communications plans collaborate closely engineering production marketing sales teams the development qa release products balance resources ensure success the entire organization develop product positioning messaging differentiates company x its features across primary market segments skills qualifications degree product design engineering strong experience dynamic product management role proven experience overseeing all elements the product development lifecycle highly effective cross-functional team management previous experience delivering finely-tuned product marketing strategies exceptional writing editing skills combined strong presentation public speaking skills preferred qualifications degree product design engineering previous software web development experience proven experience working product developer non-managerial role demonstrable knowledge sem online advertising\n",
      "   Candidate Name   Subject               Keyword Count\n",
      "0     resume2.pdf        DS     machine learning      2\n",
      "1     resume2.pdf        DE                spark      4\n",
      "2     resume2.pdf        DE               hadoop      2\n",
      "3     resume2.pdf        DE              pyspark      3\n",
      "4     resume2.pdf        DE                 hive      4\n",
      "5     resume2.pdf        DE               impala      3\n",
      "6     resume2.pdf        DE                   s3      1\n",
      "7     resume2.pdf        DE                    r      6\n",
      "8     resume2.pdf        DS  logistic regression      2\n",
      "9     resume2.pdf        DS              xgboost      2\n",
      "10    resume2.pdf  FrontEnd                flask      1\n",
      "11    resume2.pdf        DS        random forest      1\n",
      "12    resume2.pdf        DS                  svm      1\n",
      "relevance score=  0.5627379417419434\n",
      "\n",
      "resume text  sai krishna vivek +91-9701508517 linkedincom/in/yskvivek yskvivek9@gmailcom profile 2+ years experience data engineering machine learning using spark hadoop technologies strong knowledge financial analytics banking domain currently pursuing masters analytics georgia tech special electives finance time series modelling excellent organizational analytical problem-solving presentation skills experience handling multiple stake holders proactive fast learner committed learning new technologies well adept switching domains fast learning curve responsible developing first its kind analytics product finance is completely based open source technologies responsible developing efficient multilevel chemical structure-based search web application million-compound dataset csir iict part research internship education master science analytics (online) 2021(expected) georgia institute technology (35 gpa) bachelor technology (computer science engineering) 2018 gokaraju rangaraju institute engineering technology affiliated jntu (86%) intermediate narayana junior college hyderabad (905%) 2014 10th (cbse) jubilee hills public school hyderabad (10 cgpa) 2012 additional qualifications technology entrepreneurship program 2018 indian school business (isb) hyderabad (a grade) oracle certified associate (sql/plsql) skill summary big data technologies spark 24 pyspark hive impala cloud services amazon s3 storage amazon ec2 amazon emr programming languages python 3 r java c++ python libraries numpy pandas scikit scipy keras cran performanceanalytics frf2 lubridate visualization tools d3 tableau rdbms mariadb postgresql project management/dev tools eclipse github tortoise svn maven jenkins jira confluence professional experience data engineer july 2018 current development bank singapore dbs (domain banking finance) hyderabad project strategic cost allocation group finance technologies spark 24 pyspark hadoop hive impala mariadb drools java 8 python 3 sql tableau d3 shell scripting developing cost allocation product an enterprise level replacing multiple legacy applications using bigdata technologies like spark hive impala building configurable parametrized scalable robust pipelines/etl workflows structuring massive amounts multi-structured data living multiple disparate systems using data modelling techniques pyspark involved visualization reporting using tools like d3 tableau involved migration current on-premises cloud (aws) large enterprise environment replacing multiple legacy applications using bigdata technologies performing extensive exploratory data analysis close 12 billion data using sql hive providing key insights decision making multiple dimensions (customer segment product segment process segment etc) an olap data cube working multiple stakeholders business teams globally (singapore hong kong india) schema design data modelling developed rule engine using drools efficiently process complex conditions unravelled python code documentation 25 different modules poc developed multiple pocs using machine learning models part internal hackathons well versed agile methodologies (scrum kanban agile pods) using tools like jira confluence tribe/squad model projects masters 1 comparative study performance football teams using spectral clustering(graph) python 2 performed manifold learning using isomap algorithm large dataset 10000 images python 3 comparative study naïve bayes logistic regression knn xgboost classifiers predicting employee turnover 4 itinerary planner using google maps nearest neighbours python flask d3js 5 market performance comparison berkshire hathaway s&p500 based sharpe ratio treynor using performanceanalytics lubridate package r 6 handwritten digits image classification using means clustering convoluted neural networks python (keras) 7 density estimation using multidimensional gaussian kernel study whether not two brain regions likely be independent each 8 expectation maximization using gaussian mixture model handwritten digits mnist dataset python 9 analysed facebook advertising data based cost per click cost per mil cost per conversion return advertising spent etc r also performed feature selection using fractional factorial design r 10 comparative study regression tree model random forest german credit data loan approval 11 comparative study logistic regression svm xgboost credit defaulters python 12 regression working hours vs salary wage workers new jersey philadelphia by dividing workers treatment control groups 13 performed weather predictions atlanta weather data using holtwinters exponential smoothing r 14 comparative study cusum arima garch to observe the changes temperature atlanta 15 a/b testing banner ads on georgia tech website r awards stood 4th among 30 teams dbs kiosk analytics 24hrs internal hackathon\n",
      "\n",
      "jd text  job description search an experienced product manager lead multi-disciplinary development team an ideal candidate will keen eye gaps highly skilled market analyst proven ability strategize full lifecycle product production conception release may already confident leader has experience guiding cross-functional teams successful creation products improve consumer experience grow market share objectives this role drive product business-planning process across cross-functional teams the company analyze consumer needs current market trends potential partnerships an roi build vs buy perspective assess current competitor offerings seeking opportunities differentiation analyze product requirements develop appropriate programs develop implement maintain production timelines across multiple departments appraise new product ideas strategize appropriate to-market plans daily monthly responsibilities drive the execution product lifecycle processes products including product research market research competitive analysis planning positioning roadmap development requirements development product launch translate product strategy detailed requirements prototype construction final product development engineering teams create product strategy documents describe business cases high-level use cases technical requirements revenue roi analyze market data develop sales strategies define product objectives effective marketing communications plans collaborate closely engineering production marketing sales teams the development qa release products balance resources ensure success the entire organization develop product positioning messaging differentiates company x its features across primary market segments skills qualifications degree product design engineering strong experience dynamic product management role proven experience overseeing all elements the product development lifecycle highly effective cross-functional team management previous experience delivering finely-tuned product marketing strategies exceptional writing editing skills combined strong presentation public speaking skills preferred qualifications degree product design engineering previous software web development experience proven experience working product developer non-managerial role demonstrable knowledge sem online advertising\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resumes_path=os.getcwd()+\"\\\\resumes\"\n",
    "jd_path=os.getcwd()+\"\\\\jd\"\n",
    "x=RelevanceScore('resume2.pdf','jobdescription2.pdf')\n",
    "a,b,c,d=x.start_method()\n",
    "print('relevance score= ',a)\n",
    "print()\n",
    "print('resume text ',b)\n",
    "print()\n",
    "print(\"jd text \",c)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
